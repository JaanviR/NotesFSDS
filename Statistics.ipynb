{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collection, organization, analyzation, summarization,visualization of data from which we can draw conclusions about data is known as Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Types of Statistics\n",
    "## 1. Descriptive Statistics : Summarizing data using graphs(to observe a pattern) and these graphs are plotted using central tendency techniques like Mean, Median, Mode, Range, Variance or Standard deviations\n",
    "## 2. Inferential Statistics : Drawing conclusions of the given using the given population or sample of the data.Most of the times we will be able to collect only sample data and we will draw conclusions using the given sample data. We will also validate the sample data before drawing conclusions to avoid errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Population Data: Collecting data from everyone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample Data: It is nothing but the subset of the population data. Before considering it as sample data required to summarize the data we need to validate the sample data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variable : Different types of elements in the population and sample data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data : \n",
    "## Types of Data --> Categorical and Numerical \n",
    "## Categorical : Its a type of data which is in the form of groups, eg: race, sex, customer satisfication ratings, brand of a car, variety of cuisines, education,postal code, yes, no etc.,\n",
    "## Numerical : Data in the form of numbers,eg: age, height, no.of people joined in a course,etc.,\n",
    "\n",
    "## Based on level of measurement data sets can be further divided\n",
    "## Numerical --> Continuous, Discrete\n",
    "## Continuous data(Data will be in the form of floating values): eg., height(55.653455), weight(88.884859453), time, etc., \n",
    "## Discrete data(Data will be in the form of whole numbers): eg., how many cars you have, how many students are enrolled, how many children you have, score in exams, etc.,\n",
    "## Categorical --> Data will be in the form of some category eg., countries, postal codes, gender, yes or one, education qualifications, customer satisfaction ratings, etc.,\n",
    "\n",
    "\n",
    "## Based on level of measurement we can again divide the data into 2 parts:\n",
    "## Qualitative data --> Based on quality of data we can differentiate between data, there are 2 types of qualitative data(Nominal, Ordinal)\n",
    "## Nominal data(Data will not be in order and the data will be in the form numerical ): eg., postal codes, countries(we can assign a number to each country, in this case order doesn't matter), gender(can be represented as 1 or 0, 1 is for female and 0 is for male), yes or no, etc.,\n",
    "## Ordinal data(Data will be in an order): eg., education qualifications, customer satisfaction ratings, etc.,\n",
    "## Quantitative data --> Based on quantity of data we can differentiate between data, there are 2 types of quantitative data(Interval, Ratio)\n",
    "## Interval(Data will be in the form of ranges): eg., 4-7days, 3-5months, revenue($45000-$60000)\n",
    "## Ratio(Data will be in the form of percentages i.e., we will derive the percentage based on some bench mark):eg.,marks scored in an exam(90/100) i.e., out of 100 i scored 90, here 100 is the bench mark, percentage of sales(80%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment : trials\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameter : Statistical techniques like mean, median, mode etc.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central Tendency\n",
    "\n",
    "## Central Tendency techniques are required to find the y-coordinate of the Normal distribution graph(i.e., bell curve graph), inorder to plot a graph you need both x & y coordinates, the given data set will be on x-axis and y-coordinate for that particular x-coordinate is obtained by a formula which requires mean, standard deviation values to calculate y-coordinate(check out the explanation stats module-1 class-2 by sudhanshu)\n",
    "## Also the purpose of Central tendency techniques is to find the single score i.e., most typical or most representative of the entire group. It is also useful for making comparisons b/w groups of individuals or b/w sets of figures \n",
    "\n",
    "## Finding Central tendency of given dataset: There are 3 different ways to find the central tendency of given dataset\n",
    "## 1. Mean(Represents average of given dataset) --> Average (Sum of numbers/no. of numbers)\n",
    "## 2. Median(Represents middle value of given dataset) --> Middle Value (Arrange the values in ascending order and then median will be the middle value, if there are 2 middle values then median is average of two middle values)\n",
    "## 3. Mode (Represents frequency of given dataset)--> Most repeated value\n",
    "\n",
    "## Standard Deviation : Region/Measure of dispersion/spread of data from the mean(average)[both left hand side(mean-standard deviation) and right hand side(mean+standard deviation) of mean ]of dataset.\n",
    "## In simple standard deviation is used to calculate the average distance of a particular data point from the mean in a given dataset\n",
    "## Standard deviation tells us the range of data dispersion(spread of data) from the mean [both left hand side(mean-standard deviation) and right hand side(mean+standard deviation) of mean ]\n",
    "## For eg: if standard deviation is 2.96 and mean is 3.89, then we can say that the entire data is spread b/w 3.89-2.96 and 3.89+2.96 or the data ranges in b/w 3.89-2.96 and 3.89+2.96\n",
    "## If the entire dataset contains similar values(eg., 1,1,1,1,1,1,1,1) then standard deviation of that particular dataset will be close to 0\n",
    "## But it depends on whether you are considering one standard deviation or two standard deviation or three standard deviation\n",
    "\n",
    "## if you are considering one standard deviation then we can claim that 68.2% data is spread in the one standard deviation range (i.e., between mean - 1*(standard deviation) & mean + 1*(standard deviation))\n",
    "## if you are considering two standard deviations then we can claim that 95.4% data is spread in the two standard deviation range (i.e., between mean - 2*(standard deviation) & mean + 2*(standard deviation))\n",
    "## if you are considering three standard deviations then we can claim that 99.7% data is spread in the three standard deviation range (i.e., between mean - 3*(standard deviation) & mean + 3*(standard deviation))\n",
    "## Hence whenever we want to say the entire range of dataset we have to consider three standard deviation\n",
    "## If the data falls in the third standard deviation, then we can say that the data is far from mean and it is performing well\n",
    "## If standard deviation is very high the we can say that we have huge dispersion of data i.e., data is spread far from mean (the bell curve will be wide)\n",
    "## If standard deviation is very low the we can say that we have less dispersion of data i.e., most of the data is near mean (the bell curve will be steep or narrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normal Distribution --> Skewness of normally distributed data is \"zero\"\n",
    "## When the given data set graph is normally distributed(i.e., if the data set graph is in the form of a bell curve) then if we draw a line at the mean value of graph then we can say that data is symmetrical on both the sides of line\n",
    "## If the data set is normally distributed then we can say that we have a balanced dataset(means equal distribution of data on both sides of mean ) or dataset is symmetrical below and above mean \n",
    "## If the data set is normally distributed then we can say that (mean=median=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Skewness in a dataset --> If the given dataset is not normally distributed then we can say that there is skewness in data \n",
    "\n",
    "## Right Skewness/right skewed data/Positive skewness : Tail will be to the right (Tail signifies the density of the dataset)\n",
    "## If the mean of the given dataset is greater than median of the given dataset then we can say that we have positive outliers(means there are few high values in the given dataset which are considered as positive outliers and because of this mean will be shifted to right handed side) and the normal distribution graph of the given dataset will be right skewed graph, so then the given dataset is known as rightskewed data\n",
    "## Handling skewness / trying to remove skewness: Handling skewness is the process of making the dataset to be normalized or balanced\n",
    "## If you apply root to each and every element in the given dataset, then if we calculate the mean and median of this dataset(where you applied squareroot to each and every x element), then the difference between mean and median will be less when compared to the dataset without applying squareroot, and now if we plot the graph, the graph will be close to normal distribution graph but with slight skewness and we can say that this process of applying squareroot to each and every element in the given dataset is called normalization of data because here we are applying squareroot to normalize the graph(i.e., removing skewness to obtain normal distribution graph)\n",
    "\n",
    "## Normalizing the data means trying to change the scale of given dataset(for eg: by applying squareroot, log, cuberoot etc.,) \n",
    "## By applying normalization we can make the given dataset follow the normal distribution graph(where mean, median, mode will be approximately equal) and if the given data set follows normal distribution then we can say that we have balanced dataset\n",
    "\n",
    "## Left Skewness/left skewed data : Tail will be to the left (Tail signifies the density of the dataset)\n",
    "## If the mean of the given dataset is less than median of the given dataset then we can say that we have negative outliers(means there are few lower values in the given dataset which are considered as negative outliers and because of this mean will be shifted to left handed side) and the normal distribution graph of the given dataset will be left skewed graph, so then the given dataset is known as leftskewed data\n",
    "## Handling skewness / trying to remove skewness: Handling skewness is the process of making the dataset to be normalized or balanced\n",
    "\n",
    "\n",
    "## Machine learning algorithms perform better most when the given data set is balanced dataset(i.e., when given dataset follows normal distribution graph(where data is symmetrical on both sides of mean and mean,mode,median will be approximately equal ))\n",
    "\n",
    "\n",
    "## If we are given a huge dataset with more than 1 million data records and if we are asked to say whether the features(columns in a dataset) are normally distributed or not..?\n",
    "## Then we will find mean nd median for each column and say whether the columns are normally distributed or not\n",
    "## mean > median --> Right skewed(In this case we have to change the scale of the values by applying logor squareroot, etc., to make it normally distributed)\n",
    "## mean < median --> Left skewed(In this case we have to change the scale of the values by applying logor squareroot, etc., to make it normally distributed)\n",
    "## mean approximately equal to median --> Normally distributed\n",
    "\n",
    "## Right skewness is should be corrected immediately, it is of high priority, machine learning models will affect most if the dataset is right skewed rather than left skewed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Range : Maximum value - Minimum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard Normal Distribution --> Mean = 0 and Standard Deviation = 1\n",
    "## Normal Distribution --> Mean = some value and Standard Deviation = some value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
